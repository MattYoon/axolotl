{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/nas/dongkeun/.conda/envs/torch/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/mnt/nas/dongkeun/.conda/envs/torch/lib/python3.11/site-packages/transformers/utils/hub.py:124: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.\n",
      "  warnings.warn(\n",
      "Downloading shards: 100%|██████████| 6/6 [00:00<00:00, 14413.42it/s]\n",
      "Loading checkpoint shards: 100%|██████████| 6/6 [00:01<00:00,  3.58it/s]\n"
     ]
    }
   ],
   "source": [
    "#export TRANSFORMERS_CACHE=/mnt/sda/dongkeun/huggingface\n",
    "\n",
    "import os\n",
    "os.environ['TRANSFORMERS_CACHE'] = '/mnt/sda/dongkeun/huggingface'\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from peft import AutoPeftModelForCausalLM\n",
    "import torch\n",
    "\n",
    "DEVICE = 'cuda:0'\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('/home/dongkeun/axolotl/checkpoints/kogemma-hermes_en-orca-wiki-alpaca-lima')\n",
    "model = AutoPeftModelForCausalLM.from_pretrained('/home/dongkeun/axolotl/checkpoints/kogemma-hermes_en-orca-wiki-alpaca-lima/checkpoint-380', torch_dtype=torch.bfloat16).to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "adapter_model.safetensors: 100%|██████████| 200M/200M [00:25<00:00, 7.81MB/s] \n",
      "\n",
      "tokenizer.model: 100%|██████████| 4.24M/4.24M [00:01<00:00, 2.65MB/s]\n",
      "\n",
      "tokenizer.json: 100%|██████████| 17.5M/17.5M [00:03<00:00, 5.34MB/s]\n",
      "\n",
      "Upload 2 LFS files: 100%|██████████| 2/2 [00:03<00:00,  1.82s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/DKYoon/kogemma-hermes_en-orca-wiki-alpaca-lima/commit/c32a698678d3d30a6538f29e1dc58e10511555f0', commit_message='Upload tokenizer', commit_description='', oid='c32a698678d3d30a6538f29e1dc58e10511555f0', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.push_to_hub('kogemma-hermes_en-orca-wiki-alpaca-lima', private=True)\n",
    "tokenizer.push_to_hub('kogemma-hermes_en-orca-wiki-alpaca-lima', private=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|im_start|>system\n",
      "You are a helpful assistant.<|im_end|>\n",
      "<|im_start|>user\n",
      "우리나라의 전통적인 음식은 무엇인가요?<|im_end|>\n",
      "<|im_start|>assistant\n",
      "\n",
      "tensor([[     2, 235322, 235371,    571, 235298,   2997,  73786,   9020,    108,\n",
      "           2045,    708,    476,  10055,  20409,  35606, 235371,    571, 235298,\n",
      "            615,  73786,    108, 235322, 235371,    571, 235298,   2997,  73786,\n",
      "           1645,    108, 237312, 236432, 236915, 236950, 236137,  31087, 238693,\n",
      "          85024, 107342, 238186, 236648,  60331, 242513, 236589, 236361, 237526,\n",
      "         181537, 235371,    571, 235298,    615,  73786,    108, 235322, 235371,\n",
      "            571, 235298,   2997,  73786, 105776,    108]])\n"
     ]
    }
   ],
   "source": [
    "content = '''우리나라의 전통적인 음식은 무엇인가요?\n",
    "'''\n",
    "\n",
    "content = content.strip()\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": content},\n",
    "]\n",
    "\n",
    "encodeds = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
    "print(encodeds)\n",
    "encodeds = tokenizer(encodeds, return_tensors='pt')['input_ids']\n",
    "print(encodeds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bos><|im_start|>system\n",
      "You are a helpful assistant.<|im_end|>\n",
      "<|im_start|>user\n",
      "우리나라의 전통적인 음식은 무엇인가요?<|im_end|>\n",
      "<|im_start|>assistant\n",
      "우리나라의 전통적인 음식은 김치, 불고기, 비빔밥 등이 있습니다. 김치는 배추, 무, 오이 등의 채소를 소금에 절여 고춧가루, 마늘, 생강 등의 양념을 버무려 만든 음식으로, 한국인의 식탁에서 빠지지 않는 반찬입니다. 불고기는 소고기를 얇게 저며 양념에 재워 구워 먹는 음식으로, 한국인들이 좋아하는 음식 중 하나입니다. 비빔밥은 여러 가지 나물과 고기를 넣고 고추장이나 간장으로 비벼 먹는 음식으로, 한국인들이 좋아하는 음식 중 하나입니다.<|im_end|>\n",
      "<eos>\n"
     ]
    }
   ],
   "source": [
    "model_inputs = encodeds.to(DEVICE)\n",
    "generated_ids = model.generate(model_inputs, max_new_tokens=256, do_sample=False, eos_token_id=tokenizer.eos_token_id)\n",
    "decoded = tokenizer.batch_decode(generated_ids)\n",
    "print(decoded[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|im_start|>system\n",
      "You are a helpful assistant.<|im_end|>\n",
      "<|im_start|>user\n",
      "두개의 테이블 “주문”과 “고객” 가진 데이터베이스가 있습니다. “주문” 테이블에는 “주문_id” (정수), “고객_id” (정수), “주문_날짜” (날짜), “금액” (소수), “상태” (문자) 칼럼이 있고, “고객”  테이블에는 “고객_id” (정수), “이름” (문자), “이메일” (문자), “멤버쉽_상태” (문자) 칼럼이 있습니다.\n",
      "\n",
      "각 고객이 “완료”된 주문에 대해 지불한 총 금액을 반환하는 SQL 쿼리를 작성하세요. “활성화” 된 멤버쉽 상태를 가지며 지불한 총 금액이 1000이 넘는 고객에 한해 고객 이름, 이메일, 총 금액을 반환해야합니다. 결과를 지불한 총 금액에 대해 내림차순으로 정렬하세요.<|im_end|>\n",
      "<|im_start|>assistant\n",
      "\n",
      "tensor([[     2, 235322, 235371,    571, 235298,   2997,  73786,   9020,    108,\n",
      "           2045,    708,    476,  10055,  20409,  35606, 235371,    571, 235298,\n",
      "            615,  73786,    108, 235322, 235371,    571, 235298,   2997,  73786,\n",
      "           1645,    108, 238928, 237936, 236137, 108214, 210938,   1080, 237014,\n",
      "         237465, 235369, 237233,   1080, 236464, 240526, 235369,  23248, 237589,\n",
      "         112762, 239571, 131006, 236361,  55496, 235265,   1080, 237014, 237465,\n",
      "         235369, 108214, 210938,  96564,   1080, 237014, 237465, 235298,    539,\n",
      "         235369,    591, 236864, 236669,    823,   1080, 236464, 240526, 235298,\n",
      "            539, 235369,    591, 236864, 236669,    823,   1080, 237014, 237465,\n",
      "         235298, 239805, 241659, 235369,    591, 239805, 241659,    823,   1080,\n",
      "         239079, 241377, 235369,    591, 237433, 236669,    823,   1080, 237047,\n",
      "         239190, 235369,    591, 237465, 236645, 235275, 235248, 242313, 240943,\n",
      "         235832,  21167, 236464, 235269,   1080, 236464, 240526, 235369,    139,\n",
      "         239060, 210938,  96564,   1080, 236464, 240526, 235298,    539, 235369,\n",
      "            591, 236864, 236669,    823,   1080, 235832, 239295, 235369,    591,\n",
      "         237465, 236645,    823,   1080, 235832, 238519, 236666, 235369,    591,\n",
      "         237465, 236645,    823,   1080, 244407, 238364, 243274, 235298, 237047,\n",
      "         239190, 235369,    591, 237465, 236645, 235275, 235248, 242313, 240943,\n",
      "         235832,  55496, 235265,    109, 238316,  46749, 240526, 235832,   1080,\n",
      "         240206, 239077, 235369, 238602,  40712, 237465, 236179, 142192,  34805,\n",
      "         239310, 236511, 168664, 140541, 241377, 236392,  78821, 239457,  40284,\n",
      "          15678, 235248, 244489, 176947, 198766, 204551, 235265,   1080, 240090,\n",
      "         237154, 236817, 235369,  95622, 235248, 244407, 238364, 243274, 209975,\n",
      "         236791, 128753, 238986,  34805, 239310, 236511, 168664, 140541, 241377,\n",
      "         235832, 235248, 235274, 235276, 235276, 235276, 235832, 235248, 242429,\n",
      "         236214,  46749, 240526, 236179,  35191, 237138,  46749, 240526, 145887,\n",
      "         235269,  11464, 238519, 236666, 235269, 168664, 140541, 241377, 236392,\n",
      "          78821, 239457, 149735,  43395, 235265, 161050, 236791,  34805, 239310,\n",
      "         236511, 168664, 140541, 241377, 236179, 142192,  58272, 239398, 238597,\n",
      "         239937,  26291,  35467, 242507, 204551,  35606, 235371,    571, 235298,\n",
      "            615,  73786,    108, 235322, 235371,    571, 235298,   2997,  73786,\n",
      "         105776,    108]])\n"
     ]
    }
   ],
   "source": [
    "content = '''\n",
    "두개의 테이블 “주문”과 “고객” 가진 데이터베이스가 있습니다. “주문” 테이블에는 “주문_id” (정수), “고객_id” (정수), “주문_날짜” (날짜), “금액” (소수), “상태” (문자) 칼럼이 있고, “고객”  테이블에는 “고객_id” (정수), “이름” (문자), “이메일” (문자), “멤버쉽_상태” (문자) 칼럼이 있습니다.\n",
    "\n",
    "각 고객이 “완료”된 주문에 대해 지불한 총 금액을 반환하는 SQL 쿼리를 작성하세요. “활성화” 된 멤버쉽 상태를 가지며 지불한 총 금액이 1000이 넘는 고객에 한해 고객 이름, 이메일, 총 금액을 반환해야합니다. 결과를 지불한 총 금액에 대해 내림차순으로 정렬하세요.'''\n",
    "\n",
    "content = content.strip()\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": content},\n",
    "]\n",
    "\n",
    "encodeds = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
    "print(encodeds)\n",
    "encodeds = tokenizer(encodeds, return_tensors='pt')['input_ids']\n",
    "print(encodeds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bos><|im_start|>system\n",
      "You are a helpful assistant.<|im_end|>\n",
      "<|im_start|>user\n",
      "두개의 테이블 “주문”과 “고객” 가진 데이터베이스가 있습니다. “주문” 테이블에는 “주문_id” (정수), “고객_id” (정수), “주문_날짜” (날짜), “금액” (소수), “상태” (문자) 칼럼이 있고, “고객”  테이블에는 “고객_id” (정수), “이름” (문자), “이메일” (문자), “멤버쉽_상태” (문자) 칼럼이 있습니다.\n",
      "\n",
      "각 고객이 “완료”된 주문에 대해 지불한 총 금액을 반환하는 SQL 쿼리를 작성하세요. “활성화” 된 멤버쉽 상태를 가지며 지불한 총 금액이 1000이 넘는 고객에 한해 고객 이름, 이메일, 총 금액을 반환해야합니다. 결과를 지불한 총 금액에 대해 내림차순으로 정렬하세요.<|im_end|>\n",
      "<|im_start|>assistant\n",
      "```sql\n",
      "SELECT c.name, c.email, SUM(o.amount) AS total_amount\n",
      "FROM customer c\n",
      "JOIN order o ON c.customer_id = o.customer_id\n",
      "WHERE o.status = 'completed'\n",
      "  AND c.membership_status = 'active'\n",
      "  AND SUM(o.amount) > 1000\n",
      "GROUP BY c.name, c.email\n",
      "ORDER BY total_amount DESC;\n",
      "```<|im_end|>\n",
      "<eos>\n"
     ]
    }
   ],
   "source": [
    "model_inputs = encodeds.to(DEVICE)\n",
    "generated_ids = model.generate(model_inputs, max_new_tokens=256, do_sample=False, eos_token_id=tokenizer.eos_token_id)\n",
    "decoded = tokenizer.batch_decode(generated_ids)\n",
    "print(decoded[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[     2, 235322, 235371,    571, 235298,   2997,  73786,   9020,    108,\n",
      "           2045,    708,    671,  16481,  20409, 235265,   4926,    877,    692,\n",
      "           2734,    692,    476,   6911, 235265,   3883,   6789,    603,    577,\n",
      "           3407,    573,   6911,    685,  64214,    685,    692,    798, 235265,\n",
      "           7859,  19330,    573,   6911,   1742,   4065, 235290,   1547, 235290,\n",
      "           8847,    578,  22685,    861,   7161,  35606, 235371,    571, 235298,\n",
      "            615,  73786,    108, 235322, 235371,    571, 235298,   2997,  73786,\n",
      "           1645,    108, 237233, 236666,  23248, 237458,  96564, 122447, 244776,\n",
      "         236655, 235269, 235248, 240547, 236464, 235269, 213512,  17309, 237233,\n",
      "         235269, 168664, 235248, 235304, 237936, 236137,  65084, 236666, 236392,\n",
      "         235248, 241634, 236464,  55496, 235265, 122447, 244776, 236655, 236214,\n",
      "          17309, 237233, 180677,  51732, 253980,  12957, 235265, 235248, 240547,\n",
      "         236464, 236361, 126277,  80404, 245654,  43395, 235265,    108, 237700,\n",
      "         240050, 236183, 235292,    108, 235278, 235280, 235275, 122447, 244776,\n",
      "         236655, 236361,  93828, 238628, 240559, 236375,  51732, 253980,  12957,\n",
      "         235265,    591, 235305, 235275, 235248, 240547, 236464, 236361,  93828,\n",
      "         238628, 240559, 236375,  51732, 253980,  12957, 235265,    591, 235288,\n",
      "         235275,  17309, 237233, 236361,  93828, 238628, 240559, 236375,  51732,\n",
      "         253980,  12957, 235265,    109, 236864, 241305, 236392,  72163,  72159,\n",
      "          31087, 235269, 142882, 236392,  80289, 238002, 239793, 236375,  91292,\n",
      "         239969, 238597, 239969, 235248, 241364, 238721,  72163,  48060,  41645,\n",
      "         236183, 240750, 236179,  35467, 241305, 236392,  72163, 204551,  35606,\n",
      "         235371,    571, 235298,    615,  73786,    108, 235322, 235371,    571,\n",
      "         235298,   2997,  73786, 105776,    108]])\n",
      "<bos><|im_start|>system\n",
      "You are an AI assistant. User will you give you a task. Your goal is to complete the task as faithfully as you can. While performing the task think step-by-step and justify your steps.<|im_end|>\n",
      "<|im_start|>user\n",
      "과일 가게에는 복숭아, 망고, 그리고 사과, 총 3개의 과일을 팔고 있습니다. 복숭아는 사과보다 비쌉니다. 망고가 가장 저렴합니다.\n",
      "선택지:\n",
      "(A) 복숭아가 두번째로 비쌉니다. (B) 망고가 두번째로 비쌉니다. (C) 사과가 두번째로 비쌉니다.\n",
      "\n",
      "정답을 말하기 전, 생각을 단계별로 차근차근 먼저 말하고 마지막에 정답을 말하세요.<|im_end|>\n",
      "<|im_start|>assistant\n",
      "먼저 주어진 정보를 분석해 보겠습니다:\n",
      "\n",
      "1. 과일 가게에는 복숭아, 망고, 사과가 있습니다.\n",
      "2. 복숭아는 사과보다 비쌉니다.\n",
      "3. 망고가 가장 저렴합니다.\n",
      "\n",
      "이제 이 정보를 바탕으로 주어진 선택지 중 하나를 결정해 보겠습니다.\n",
      "\n",
      "(A) 복숭아가 두번째로 비쌉니다.\n",
      "(B) 망고가 두번째로 비쌉니다.\n",
      "(C) 사과가 두번째로 비쌉니다.\n",
      "\n",
      "복숭아가 사과보다 비 AspNetCore입니다. 따라서 복숭아가 사과보다 비 AspNetCore입니다.\n",
      "\n",
      "망고가 가장 저렴합니다. 따라서 복숭아보다 저렴합니다.\n",
      "\n",
      "사과가 복숭아보다 비 AspNetCore입니다. 따라서 사과는 복숭아보다 비 AspNetCore입니다.\n",
      "\n",
      "따라서 복숭아는 사과보다 비 AspNetCore입니다. 따라서 복숭아는 사과보다 비 AspNetCore입니다.\n",
      "\n",
      "따라서 정답은 (A) 복숭아가 두번째로 비쌉니다.<|im_end|>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "content = '''\n",
    "과일 가게에는 복숭아, 망고, 그리고 사과, 총 3개의 과일을 팔고 있습니다. 복숭아는 사과보다 비쌉니다. 망고가 가장 저렴합니다.\n",
    "선택지:\n",
    "(A) 복숭아가 두번째로 비쌉니다. (B) 망고가 두번째로 비쌉니다. (C) 사과가 두번째로 비쌉니다.\n",
    "\n",
    "정답을 말하기 전, 생각을 단계별로 차근차근 먼저 말하고 마지막에 정답을 말하세요.\n",
    "'''\n",
    "\n",
    "content = content.strip()\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are an AI assistant. User will you give you a task. Your goal is to complete the task as faithfully as you can. While performing the task think step-by-step and justify your steps.\"},\n",
    "    {\"role\": \"user\", \"content\": content},\n",
    "]\n",
    "\n",
    "encodeds = tokenizer.apply_chat_template(messages, add_generation_prompt=True, tokenize=False)\n",
    "encodeds = tokenizer(encodeds, return_tensors='pt')['input_ids']\n",
    "print(encodeds)\n",
    "model_inputs = encodeds.to(DEVICE)\n",
    "generated_ids = model.generate(model_inputs, max_new_tokens=256, do_sample=False, eos_token_id=tokenizer.eos_token_id)\n",
    "decoded = tokenizer.batch_decode(generated_ids)\n",
    "print(decoded[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|im_start|>system\n",
      "You are an AI assistant. User will you give you a task. Your goal is to complete the task as faithfully as you can. While performing the task think step-by-step and justify your steps.<|im_end|>\n",
      "<|im_start|>user\n",
      "'employees'라는 테이블이 있고, 이 테이블에는 'id' (정수), 'name' (텍스트), 'position' (텍스트), 'salary' (정수)라는 컬럼이 있습니다. 연봉이 50000 이상이며 직책이 'Manager'인 직원의 이름과 연봉을 찾는 SQL 쿼리를 작성하세요.<|im_end|>\n",
      "<|im_start|>assistant\n",
      "연봉이 50000 이상이고 직책이 'Manager'인 직원의 이름과 연봉을 찾는 SQL 쿼리를 작성하기 위해 다음 단계를 수행합니다:\n",
      "\n",
      "1. 'employees' 테이블에서 'position' 컬럼에 'Manager'라는 값이 있는 행을 식별합니다.\n",
      "2. 'position' 컬럼에서 'Manager'라는 값이 있는 행을 식별한 후, 'salary' 컬럼에서 50000 이상의 값이 있는 행을 필터링합니다.\n",
      "3. 'salary' 컬럼에서 50000 이상의 값이 있는 행을 식별한 후, 'name' 컬럼에서 해당 행의 이름을 검색합니다.\n",
      "\n",
      "SQL 쿼리는 다음과 같습니다:\n",
      "\n",
      "SELECT name, salary\n",
      "FROM employees\n",
      "WHERE position = 'Manager'\n",
      "AND salary > 50000;\n",
      "\n",
      "이 쿼리는 'position' 컬럼에서 'Manager'라는 값이 있는 행을 필터링하고 'salary' 컬럼에서 50000 이상의 값이 있는 행을 필터링합니다. 그런 다음 'name' 컬럼에서 해당 행의 이름을 검색합니다.<|im_end|>\n",
      "<eos>\n"
     ]
    }
   ],
   "source": [
    "content = '''\n",
    "'employees'라는 테이블이 있고, 이 테이블에는 'id' (정수), 'name' (텍스트), 'position' (텍스트), 'salary' (정수)라는 컬럼이 있습니다. 연봉이 50000 이상이며 직책이 'Manager'인 직원의 이름과 연봉을 찾는 SQL 쿼리를 작성하세요.\n",
    "'''\n",
    "\n",
    "content = content.strip()\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are an AI assistant. User will you give you a task. Your goal is to complete the task as faithfully as you can. While performing the task think step-by-step and justify your steps.\"},\n",
    "    {\"role\": \"user\", \"content\": content},\n",
    "]\n",
    "\n",
    "encodeds = tokenizer.apply_chat_template(messages, return_tensors='pt', add_generation_prompt=True)\n",
    "model_inputs = encodeds.to(DEVICE)\n",
    "generated_ids = model.generate(model_inputs, max_new_tokens=512, do_sample=False, eos_token_id=tokenizer.eos_token_id)\n",
    "decoded = tokenizer.batch_decode(generated_ids)\n",
    "print(decoded[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
